{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Lease\n",
    "\n",
    "Follow the guide provided by the professor and reserve a lease.\n",
    "\n",
    "### Naming Convention\n",
    "\n",
    "NodeType_project##: `gpu_rtx_6000_project46`\n",
    "\n",
    "### Available Resource\n",
    "Bare Metal GPU Resources (4/12 - 5/1+)\n",
    "\n",
    "- **CHI@UC**\n",
    "  - **gpu_rtx6000**: RTX6000 GPU (variable number)\n",
    "    - General model training/inference\n",
    "  - **compute_gigaio**: A100 80GB GPU (variable number)\n",
    "    - Large model training/inference\n",
    "  - **gpu_a100_pcie** (J0BG3Q3 or 307G3Q3): 4× A100 80GB GPUs\n",
    "    - Reserved 4/12–5/6\n",
    "    - Distributed training for very large models\n",
    "\n",
    "- **CHI@TACC**\n",
    "  - **compute_liqid**: A100 40GB GPU (4 nodes)\n",
    "    - General training/inference, NVIDIA Triton service\n",
    "  - **gpu_mi100**: 2× MI100 AMD GPUs (2 nodes)\n",
    "    - General model training/inference\n",
    "\n",
    "## Launch and set up Chameleon server - with python-chi\n",
    "\n",
    "At the beginning of the lease time for your bare metal server, we will bring up our GPU instance. We will use the `python-chi` Python API to Chameleon to provision our server.\n",
    "\n",
    "We will execute the cells in this notebook inside the **Chameleon Jupyter environment**.\n",
    "\n",
    "Run the following cell, and make sure the correct project is selected. Also, **change the site to CHI@TACC or CHI@UC**, depending on where your reservation is, and **edit your lease name**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHAMELEON_SITE=\"CHI@UC\"  # EDIT THIS\n",
    "LEASE_NAME=\"compute_gigaio_project46\"  # EDIT THIS\n",
    "\n",
    "GITHUB_USERNAME=\"\"\n",
    "GITHUB_EMAIL=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from chi import server, context, lease\n",
    "import os\n",
    "\n",
    "context.version = \"1.0\" \n",
    "context.choose_project()\n",
    "context.choose_site(default=CHAMELEON_SITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l = lease.get_lease(f\"{LEASE_NAME}\") \n",
    "l.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The status should show as “ACTIVE” now that we are past the lease start time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the lease to bring up a server with the `CC-Ubuntu24.04-CUDA` disk image.\n",
    "\n",
    "> **Note**: the following cell brings up a server only if you don’t already have one with the same name! (Regardless of its error state.) If you have a server in ERROR state already, delete it first in the Horizon GUI before you run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "username = os.getenv('USER') # all exp resources will have this prefix\n",
    "s = server.Server(\n",
    "    f\"node-{LEASE_NAME}-{username}\", \n",
    "    reservation_id=l.node_reservations[0][\"id\"],\n",
    "    image_name=\"CC-Ubuntu24.04-CUDA\"\n",
    ")\n",
    "s.submit(idempotent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: security groups are not used at Chameleon bare metal sites, so we do not have to configure any security groups on this instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we’ll associate a floating IP with the instance, so that we can access it over SSH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.associate_floating_ip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.refresh()\n",
    "s.check_connectivity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output below, make a note of the floating IP that has been assigned to your instance (in the “Addresses” row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.refresh()\n",
    "s.show(type=\"widget\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up SSH Key from your local terminal\n",
    "\n",
    "#### (One time) Prepare Your SSH Key (on Your Local Machine) if you have not.\n",
    "\n",
    "Before interacting with the remote server through Jupyter Notebook, it is recommended to prepare an SSH key locally, instead of generating it inside the Notebook, to keep your private key secure.\n",
    "\n",
    "Step-by-Step:\n",
    "1.\tGenerate an SSH key locally (replace the filename with your preferred name, e.g., id_ed25519_chameleon_git):\n",
    "\n",
    "    ssh-keygen -t ed25519 -C \"your_email@example.com\" -f ~/.ssh/id_ed25519_chameleon_git\n",
    "\n",
    "- This command will generate two files:\n",
    "- Private key: ~/.ssh/id_ed25519_chameleon_git\n",
    "- Public key: ~/.ssh/id_ed25519_chameleon_git.pub\n",
    "\n",
    "2.\tAdd the public key to your GitHub account:\n",
    "\n",
    "- Go to GitHub → Settings → SSH and GPG keys → New SSH key.\n",
    "- Copy the contents of id_ed25519_chameleon_git.pub and paste it there.\n",
    "\n",
    "\n",
    "#### Copy Key, Setup Permission and Config\n",
    "\n",
    "Edit the following and run in your **local terminal**\n",
    "\n",
    "    REMOTE_USER=\"cc\"\n",
    "    REMOTE_HOST=\"192.5.87.126\"   # *EDIT* floating IP address\n",
    "    REMOTE_SSH_DIR=\"~/.ssh\"\n",
    "    KEY_NAME=\"id_ed25519_chameleon_git\" # *EDIT* your key name\n",
    "\n",
    "    # Your Authentication key\n",
    "    LOCAL_PRIVATE_KEY=\"$HOME/.ssh/${KEY_NAME}\" \n",
    "    LOCAL_PUBLIC_KEY=\"$HOME/.ssh/${KEY_NAME}.pub\"\n",
    "\n",
    "    # Your Hugging Face token\n",
    "    HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}\n",
    "\n",
    "    # Step 1: mkdir + chmod .ssh\n",
    "    ssh -i ~/.ssh/id_rsa_chameleon ${REMOTE_USER}@${REMOTE_HOST} \"mkdir -p ${REMOTE_SSH_DIR} && chmod 700 ${REMOTE_SSH_DIR}\"\n",
    "\n",
    "    # Step 2: Copy SSH private/public key\n",
    "    scp -i ~/.ssh/id_rsa_chameleon \"$LOCAL_PRIVATE_KEY\" ${REMOTE_USER}@${REMOTE_HOST}:${REMOTE_SSH_DIR}/${KEY_NAME}\n",
    "    scp -i ~/.ssh/id_rsa_chameleon \"$LOCAL_PUBLIC_KEY\" ${REMOTE_USER}@${REMOTE_HOST}:${REMOTE_SSH_DIR}/${KEY_NAME}.pub\n",
    "    \n",
    "    # Step 3: Setup permission\n",
    "    ssh -i ~/.ssh/id_rsa_chameleon ${REMOTE_USER}@${REMOTE_HOST} \"chmod 600 ${REMOTE_SSH_DIR}/${KEY_NAME} && chmod 644 ${REMOTE_SSH_DIR}/${KEY_NAME}.pub\"\n",
    "\n",
    "    # Step 4: Create SSH config\n",
    "    ssh -i ~/.ssh/id_rsa_chameleon ${REMOTE_USER}@${REMOTE_HOST} \"echo -e '\\\n",
    "    Host github.com\\n\\\n",
    "        HostName github.com\\n\\\n",
    "        User git\\n\\\n",
    "        IdentityFile ~/.ssh/${KEY_NAME}\\n\\\n",
    "        StrictHostKeyChecking no\\n\\\n",
    "    ' >> ${REMOTE_SSH_DIR}/config && chmod 600 ${REMOTE_SSH_DIR}/config\"\n",
    "\n",
    "    # Step 5: Export HUGGINGFACE_TOKEN to remote .bashrc (or create .env)\n",
    "    # If you have Hugging Face token on your local machine, this step will copy it to the server\n",
    "    if [ -z \"$HUGGINGFACE_TOKEN\" ]; then\n",
    "      echo \"HUGGINGFACE_TOKEN not set locally. Ignored token transfer.\"\n",
    "    else\n",
    "      echo \"Uploading HUGGINGFACE_TOKEN to remote...\"\n",
    "\n",
    "      ssh -i ~/.ssh/id_rsa_chameleon ${REMOTE_USER}@${REMOTE_HOST} \"echo 'export HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}' >> ~/.bashrc\"\n",
    "    fi\n",
    "\n",
    "\n",
    "### Retrieve the project on the instance\n",
    "\n",
    "Now, we can use `python-chi` to execute commands on the instance, to set it up. We’ll start by retrieving the code and other materials on the instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.execute(\"git clone git@github.com:LawrenceLu0904/Fine-Tuning-Taiwanese-Hokkien-LLM-for-Medical-Advising.git\")\n",
    "\n",
    "s.execute(f'git config --global user.name {GITHUB_USERNAME}')\n",
    "s.execute(f'git config --global user.email {GITHUB_EMAIL}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Docker\n",
    "\n",
    "To use common deep learning frameworks like Tensorflow or PyTorch, and ML training platforms like MLFlow and Ray, we can run containers that have all the prerequisite libraries necessary for these frameworks. Here, we will set up the container framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.execute(\"curl -sSL https://get.docker.com/ | sudo sh\")\n",
    "s.execute(\"sudo groupadd -f docker; sudo usermod -aG docker $USER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the NVIDIA container toolkit\n",
    "\n",
    "We will also install the NVIDIA container toolkit, with which we can access GPUs from inside our containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.execute(\"curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n",
    "  && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n",
    "    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n",
    "    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\")\n",
    "s.execute(\"sudo apt update\")\n",
    "s.execute(\"sudo apt-get install -y nvidia-container-toolkit\")\n",
    "s.execute(\"sudo nvidia-ctk runtime configure --runtime=docker\")\n",
    "# for https://github.com/NVIDIA/nvidia-container-toolkit/issues/48\n",
    "s.execute(\"sudo jq 'if has(\\\"exec-opts\\\") then . else . + {\\\"exec-opts\\\": [\\\"native.cgroupdriver=cgroupfs\\\"]} end' /etc/docker/daemon.json | sudo tee /etc/docker/daemon.json.tmp > /dev/null && sudo mv /etc/docker/daemon.json.tmp /etc/docker/daemon.json\")\n",
    "s.execute(\"sudo systemctl restart docker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Project Dependencies for inferencing (Optional)\n",
    "\n",
    "The following steps are just for easier execution and are basically same with Instruction Steps 1 to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_dir = \"~/Fine-Tuning-Taiwanese-Hokkien-LLM-for-Medical-Advising\"\n",
    "\n",
    "# Create a Virtual environment: (taigi-env) or any name you prefer\n",
    "s.execute(f\"cd {project_dir} && python3 -m venv taigi-env\")\n",
    "s.execute(f\"cd {project_dir} && source taigi-env/bin/activate\")\n",
    "\n",
    "s.execute(f\"cd {project_dir} && ./taigi-env/bin/pip -V\")\n",
    "\n",
    "\n",
    "# Install requirement packages in your virtual environment\n",
    "s.execute(f\"cd {project_dir} && ./taigi-env/bin/pip install -r requirements.txt\")\n",
    "\n",
    "# There are some packages that need to be installed manually (follow the instructions below):\n",
    "s.execute(f\"cd {project_dir} && ./taigi-env/bin/pip install sentencepiece --prefer-binary\")\n",
    "s.execute(f\"cd {project_dir} && ./taigi-env/bin/pip install datasets\")\n",
    "\n",
    "# Reinstall bitsandbytes to prevent RuntimeError\n",
    "s.execute(f\"cd {project_dir} && ./taigi-env/bin/pip uninstall bitsandbytes -y\")\n",
    "s.execute(f\"cd {project_dir} && ./taigi-env/bin/pip install bitsandbytes --no-cache-dir\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Login to HUGGINGFACE\n",
    "\n",
    "Run if you have HUGGINGFACE_TOKEN on your local machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Directly store the huggingface token into the cache\n",
    "s.execute('''\n",
    "token=$(grep HUGGINGFACE_TOKEN ~/.bashrc | tail -n 1 | sed 's/.*=//g' | tr -d '\"')\n",
    "mkdir -p ~/.cache/huggingface\n",
    "echo \"$token\" > ~/.cache/huggingface/token\n",
    "echo \"[TOKEN STORED]\"\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or run edit and add your token here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Login to HuggingFace for base model authorization\n",
    "huggingface_token = \"YOUR_huggingface_token\"\n",
    "s.execute(f'''\n",
    "cd {project_dir} && ./taigi-env/bin/huggingface-cli login --token \"{huggingface_token}\"\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open an SSH session\n",
    "\n",
    "Finally, open an SSH sesson on your server. From your local terminal, run\n",
    "\n",
    "    ssh -i ~/.ssh/id_rsa_chameleon cc@A.B.C.D\n",
    "\n",
    "where\n",
    "\n",
    "-   in place of `~/.ssh/id_rsa_chameleon`, substitute the path to your own key that you had uploaded to CHI@TACC\n",
    "-   in place of `A.B.C.D`, use the floating IP address you just associated to your instance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
