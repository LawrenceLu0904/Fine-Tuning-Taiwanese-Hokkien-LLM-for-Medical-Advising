{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 707,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01415929203539823,
      "grad_norm": 0.6002803444862366,
      "learning_rate": 4.9787535410764873e-05,
      "loss": 1.8994,
      "step": 10
    },
    {
      "epoch": 0.02831858407079646,
      "grad_norm": 0.8372678160667419,
      "learning_rate": 4.9551463644948064e-05,
      "loss": 1.7699,
      "step": 20
    },
    {
      "epoch": 0.04247787610619469,
      "grad_norm": 0.7904869914054871,
      "learning_rate": 4.9315391879131255e-05,
      "loss": 1.5223,
      "step": 30
    },
    {
      "epoch": 0.05663716814159292,
      "grad_norm": 0.44287124276161194,
      "learning_rate": 4.9079320113314446e-05,
      "loss": 1.3668,
      "step": 40
    },
    {
      "epoch": 0.07079646017699115,
      "grad_norm": 0.5159350633621216,
      "learning_rate": 4.884324834749764e-05,
      "loss": 1.3055,
      "step": 50
    },
    {
      "epoch": 0.08495575221238938,
      "grad_norm": 0.412307471036911,
      "learning_rate": 4.8607176581680834e-05,
      "loss": 1.2721,
      "step": 60
    },
    {
      "epoch": 0.09911504424778761,
      "grad_norm": 0.4920317232608795,
      "learning_rate": 4.8371104815864025e-05,
      "loss": 1.2537,
      "step": 70
    },
    {
      "epoch": 0.11327433628318584,
      "grad_norm": 0.4459075331687927,
      "learning_rate": 4.8135033050047215e-05,
      "loss": 1.2447,
      "step": 80
    },
    {
      "epoch": 0.12743362831858407,
      "grad_norm": 0.45253387093544006,
      "learning_rate": 4.7898961284230406e-05,
      "loss": 1.2661,
      "step": 90
    },
    {
      "epoch": 0.1415929203539823,
      "grad_norm": 0.49597468972206116,
      "learning_rate": 4.7662889518413604e-05,
      "loss": 1.3221,
      "step": 100
    },
    {
      "epoch": 0.15575221238938053,
      "grad_norm": 0.43525004386901855,
      "learning_rate": 4.7426817752596795e-05,
      "loss": 1.2543,
      "step": 110
    },
    {
      "epoch": 0.16991150442477876,
      "grad_norm": 0.43994957208633423,
      "learning_rate": 4.7190745986779985e-05,
      "loss": 1.2519,
      "step": 120
    },
    {
      "epoch": 0.184070796460177,
      "grad_norm": 0.4637891948223114,
      "learning_rate": 4.6954674220963176e-05,
      "loss": 1.2226,
      "step": 130
    },
    {
      "epoch": 0.19823008849557522,
      "grad_norm": 0.42566266655921936,
      "learning_rate": 4.671860245514637e-05,
      "loss": 1.261,
      "step": 140
    },
    {
      "epoch": 0.21238938053097345,
      "grad_norm": 0.5060666799545288,
      "learning_rate": 4.648253068932956e-05,
      "loss": 1.2235,
      "step": 150
    },
    {
      "epoch": 0.22654867256637168,
      "grad_norm": 0.4051678478717804,
      "learning_rate": 4.624645892351275e-05,
      "loss": 1.1965,
      "step": 160
    },
    {
      "epoch": 0.2407079646017699,
      "grad_norm": 0.5324794054031372,
      "learning_rate": 4.6010387157695946e-05,
      "loss": 1.2226,
      "step": 170
    },
    {
      "epoch": 0.25486725663716814,
      "grad_norm": 0.5153335928916931,
      "learning_rate": 4.5774315391879137e-05,
      "loss": 1.2461,
      "step": 180
    },
    {
      "epoch": 0.26902654867256637,
      "grad_norm": 0.4866899847984314,
      "learning_rate": 4.553824362606233e-05,
      "loss": 1.2184,
      "step": 190
    },
    {
      "epoch": 0.2831858407079646,
      "grad_norm": 0.4806630313396454,
      "learning_rate": 4.530217186024552e-05,
      "loss": 1.1984,
      "step": 200
    },
    {
      "epoch": 0.2973451327433628,
      "grad_norm": 0.4258778691291809,
      "learning_rate": 4.506610009442871e-05,
      "loss": 1.25,
      "step": 210
    },
    {
      "epoch": 0.31150442477876106,
      "grad_norm": 0.4819760322570801,
      "learning_rate": 4.48300283286119e-05,
      "loss": 1.2128,
      "step": 220
    },
    {
      "epoch": 0.3256637168141593,
      "grad_norm": 0.46180063486099243,
      "learning_rate": 4.459395656279509e-05,
      "loss": 1.2339,
      "step": 230
    },
    {
      "epoch": 0.3398230088495575,
      "grad_norm": 0.48273250460624695,
      "learning_rate": 4.435788479697828e-05,
      "loss": 1.2355,
      "step": 240
    },
    {
      "epoch": 0.35398230088495575,
      "grad_norm": 0.5231866240501404,
      "learning_rate": 4.412181303116147e-05,
      "loss": 1.2198,
      "step": 250
    },
    {
      "epoch": 0.368141592920354,
      "grad_norm": 0.5037385821342468,
      "learning_rate": 4.388574126534466e-05,
      "loss": 1.222,
      "step": 260
    },
    {
      "epoch": 0.3823008849557522,
      "grad_norm": 0.4840356409549713,
      "learning_rate": 4.3649669499527853e-05,
      "loss": 1.1879,
      "step": 270
    },
    {
      "epoch": 0.39646017699115044,
      "grad_norm": 0.5632855296134949,
      "learning_rate": 4.341359773371105e-05,
      "loss": 1.1889,
      "step": 280
    },
    {
      "epoch": 0.41061946902654867,
      "grad_norm": 0.543155312538147,
      "learning_rate": 4.317752596789424e-05,
      "loss": 1.229,
      "step": 290
    },
    {
      "epoch": 0.4247787610619469,
      "grad_norm": 0.5524522066116333,
      "learning_rate": 4.294145420207743e-05,
      "loss": 1.155,
      "step": 300
    },
    {
      "epoch": 0.4389380530973451,
      "grad_norm": 0.4879978895187378,
      "learning_rate": 4.270538243626063e-05,
      "loss": 1.2414,
      "step": 310
    },
    {
      "epoch": 0.45309734513274336,
      "grad_norm": 0.5435587763786316,
      "learning_rate": 4.246931067044382e-05,
      "loss": 1.2602,
      "step": 320
    },
    {
      "epoch": 0.4672566371681416,
      "grad_norm": 0.6195966005325317,
      "learning_rate": 4.223323890462701e-05,
      "loss": 1.2631,
      "step": 330
    },
    {
      "epoch": 0.4814159292035398,
      "grad_norm": 0.5325483679771423,
      "learning_rate": 4.19971671388102e-05,
      "loss": 1.2138,
      "step": 340
    },
    {
      "epoch": 0.49557522123893805,
      "grad_norm": 0.5303341746330261,
      "learning_rate": 4.176109537299339e-05,
      "loss": 1.2729,
      "step": 350
    },
    {
      "epoch": 0.5097345132743363,
      "grad_norm": 0.5033726096153259,
      "learning_rate": 4.1525023607176584e-05,
      "loss": 1.2563,
      "step": 360
    },
    {
      "epoch": 0.5238938053097345,
      "grad_norm": 0.5167916417121887,
      "learning_rate": 4.1288951841359775e-05,
      "loss": 1.2134,
      "step": 370
    },
    {
      "epoch": 0.5380530973451327,
      "grad_norm": 0.6657823324203491,
      "learning_rate": 4.1052880075542965e-05,
      "loss": 1.1998,
      "step": 380
    },
    {
      "epoch": 0.552212389380531,
      "grad_norm": 0.5898147225379944,
      "learning_rate": 4.0816808309726156e-05,
      "loss": 1.216,
      "step": 390
    },
    {
      "epoch": 0.5663716814159292,
      "grad_norm": 0.5561444163322449,
      "learning_rate": 4.058073654390935e-05,
      "loss": 1.1963,
      "step": 400
    },
    {
      "epoch": 0.5805309734513274,
      "grad_norm": 0.5273023247718811,
      "learning_rate": 4.0344664778092544e-05,
      "loss": 1.1501,
      "step": 410
    },
    {
      "epoch": 0.5946902654867257,
      "grad_norm": 0.5796951651573181,
      "learning_rate": 4.0108593012275735e-05,
      "loss": 1.1702,
      "step": 420
    },
    {
      "epoch": 0.6088495575221239,
      "grad_norm": 0.5083635449409485,
      "learning_rate": 3.9872521246458926e-05,
      "loss": 1.1902,
      "step": 430
    },
    {
      "epoch": 0.6230088495575221,
      "grad_norm": 0.5843495726585388,
      "learning_rate": 3.963644948064212e-05,
      "loss": 1.2182,
      "step": 440
    },
    {
      "epoch": 0.6371681415929203,
      "grad_norm": 0.6568189859390259,
      "learning_rate": 3.940037771482531e-05,
      "loss": 1.2314,
      "step": 450
    },
    {
      "epoch": 0.6513274336283186,
      "grad_norm": 0.5582744479179382,
      "learning_rate": 3.91643059490085e-05,
      "loss": 1.2208,
      "step": 460
    },
    {
      "epoch": 0.6654867256637168,
      "grad_norm": 0.613336443901062,
      "learning_rate": 3.892823418319169e-05,
      "loss": 1.2834,
      "step": 470
    },
    {
      "epoch": 0.679646017699115,
      "grad_norm": 0.5596470236778259,
      "learning_rate": 3.8692162417374886e-05,
      "loss": 1.2006,
      "step": 480
    },
    {
      "epoch": 0.6938053097345133,
      "grad_norm": 0.5938729643821716,
      "learning_rate": 3.845609065155808e-05,
      "loss": 1.1593,
      "step": 490
    },
    {
      "epoch": 0.7079646017699115,
      "grad_norm": 0.6184684634208679,
      "learning_rate": 3.822001888574127e-05,
      "loss": 1.2383,
      "step": 500
    },
    {
      "epoch": 0.7221238938053097,
      "grad_norm": 0.5908363461494446,
      "learning_rate": 3.798394711992446e-05,
      "loss": 1.2124,
      "step": 510
    },
    {
      "epoch": 0.736283185840708,
      "grad_norm": 0.592547595500946,
      "learning_rate": 3.774787535410765e-05,
      "loss": 1.1858,
      "step": 520
    },
    {
      "epoch": 0.7504424778761062,
      "grad_norm": 0.5176660418510437,
      "learning_rate": 3.751180358829085e-05,
      "loss": 1.2101,
      "step": 530
    },
    {
      "epoch": 0.7646017699115044,
      "grad_norm": 0.5728599429130554,
      "learning_rate": 3.727573182247404e-05,
      "loss": 1.203,
      "step": 540
    },
    {
      "epoch": 0.7787610619469026,
      "grad_norm": 0.559916079044342,
      "learning_rate": 3.703966005665723e-05,
      "loss": 1.216,
      "step": 550
    },
    {
      "epoch": 0.7929203539823009,
      "grad_norm": 0.6526515483856201,
      "learning_rate": 3.680358829084042e-05,
      "loss": 1.1734,
      "step": 560
    },
    {
      "epoch": 0.8070796460176991,
      "grad_norm": 0.6321780681610107,
      "learning_rate": 3.656751652502361e-05,
      "loss": 1.2365,
      "step": 570
    },
    {
      "epoch": 0.8212389380530973,
      "grad_norm": 0.5667020082473755,
      "learning_rate": 3.63314447592068e-05,
      "loss": 1.2256,
      "step": 580
    },
    {
      "epoch": 0.8353982300884956,
      "grad_norm": 0.6406606435775757,
      "learning_rate": 3.609537299338999e-05,
      "loss": 1.22,
      "step": 590
    },
    {
      "epoch": 0.8495575221238938,
      "grad_norm": 0.617275595664978,
      "learning_rate": 3.585930122757318e-05,
      "loss": 1.2128,
      "step": 600
    },
    {
      "epoch": 0.863716814159292,
      "grad_norm": 0.5522498488426208,
      "learning_rate": 3.562322946175637e-05,
      "loss": 1.2045,
      "step": 610
    },
    {
      "epoch": 0.8778761061946903,
      "grad_norm": 0.599518895149231,
      "learning_rate": 3.5387157695939564e-05,
      "loss": 1.1979,
      "step": 620
    },
    {
      "epoch": 0.8920353982300885,
      "grad_norm": 0.6753330230712891,
      "learning_rate": 3.5151085930122755e-05,
      "loss": 1.2199,
      "step": 630
    },
    {
      "epoch": 0.9061946902654867,
      "grad_norm": 0.5639086961746216,
      "learning_rate": 3.4915014164305945e-05,
      "loss": 1.1818,
      "step": 640
    },
    {
      "epoch": 0.9203539823008849,
      "grad_norm": 0.5983591079711914,
      "learning_rate": 3.467894239848914e-05,
      "loss": 1.2029,
      "step": 650
    },
    {
      "epoch": 0.9345132743362832,
      "grad_norm": 0.6112005114555359,
      "learning_rate": 3.4442870632672334e-05,
      "loss": 1.1931,
      "step": 660
    },
    {
      "epoch": 0.9486725663716814,
      "grad_norm": 0.606945276260376,
      "learning_rate": 3.4206798866855524e-05,
      "loss": 1.1001,
      "step": 670
    },
    {
      "epoch": 0.9628318584070796,
      "grad_norm": 0.5534370541572571,
      "learning_rate": 3.3970727101038715e-05,
      "loss": 1.1406,
      "step": 680
    },
    {
      "epoch": 0.9769911504424779,
      "grad_norm": 0.6160436272621155,
      "learning_rate": 3.373465533522191e-05,
      "loss": 1.196,
      "step": 690
    },
    {
      "epoch": 0.9911504424778761,
      "grad_norm": 0.6889746785163879,
      "learning_rate": 3.3498583569405103e-05,
      "loss": 1.1781,
      "step": 700
    }
  ],
  "logging_steps": 10,
  "max_steps": 2118,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.3287002811701658e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
